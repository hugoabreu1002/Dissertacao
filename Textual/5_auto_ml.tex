\chapter{Auto ML e Modelos Propostos}
\label{cap:mod_props}

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

\section{Meta-heurísticas}

\subsection{ACO}

Cada formiga precisa construir uma solução para se mover pelo gráfico. Para selecionar a próxima aresta em seu passeio, uma formiga irá considerar o comprimento de cada aresta disponível a partir de sua posição atual, bem como o nível de feromônio correspondente. Em cada etapa do algoritmo, cada formiga se move de um estado $\textit{x}$ para um outro $\textit{y}$, correspondendo a uma solução intermediária mais completa. A partir disto, cada formiga $k$ calcula um grupo $A_{k}(x)$ de passeios movimentos factíveis a partir da sua posição atual para cada iteração, a formiga se move então para um desses novos estados possíveis de acordo com a probabilidade. Para a formiga $k$, a probabilidade $p_{xy}^{k}$ de se mover do estado $x$ para o estado $y$ depende da combinação de dois valores, a atratividade $\eta _{xy}$ dessa mudança, alguma heurística indicando a conveniência a priori desse movimento e a quantidade de feromônio depositada na trilha $\tau _{xy}$, indicando o quão proficiente ele foi no passado para fazer aquele movimento específico. O nível da trilha representa a posteriori uma indicação da conveniência desse movimento.

Por fim cada formiga $k$ se move entre os estados $x$ e $y$ com uma probabilidade conforme a equação \ref{eq:aco_prob}.

\begin{equation}
\label{eq:aco_prob}
    p_{xy}^k =
    \frac
    { (\tau_{xy}^{\alpha}) (\eta_{xy}^{\beta}) }
    { \sum_{z\in \mathrm{allowed}_x} (\tau_{xz}^{\alpha}) (\eta_{xz}^{\beta}) }
\end{equation}

em que $\tau _{xy}$ é a quantidade de ferormônio depositado para a mudança de estado de $x$ para $y$, $\alpha \geq 0$  é um parâmetro de controle da influência de $\tau _{xy}$,$\eta _{xy}$ é a desejabilidade $xy$ tipicamente $1/d_{{xy}}$, em que $d$ é a distância entre os vértices $\textit{x}$ e $\textit{y}$, tendo $\beta  \geq 1$ como seu parâmetro de controle.

As trilhas geralmente são atualizadas quando todas as formigas concluem sua solução, aumentando ou diminuindo o nível das trilhas correspondentes aos movimentos que fizeram parte de soluções "boas" ou "ruins", respectivamente. Um exemplo de regra de atualização global de feromônio é como na equação \ref{eq:aco_delta_tal}

\begin{equation}
\label{eq:aco_delta_tal}
    \Delta{\tau^{k}_{xy}} =
    \begin{cases}
    Q/L_k & \mbox{if ant }k\mbox{ uses curve }xy\mbox{ in its tour} \\
    0 & \mbox{otherwise}
    \end{cases}
\end{equation}

$\rho$ é o coeficiente de evaporação de feromônio e $\Delta \tau _{xy}^{k}$ é a quantidade de feromônio que será depositada pela formiga $k$th ant como mostrado na equação abaixo \ref{eq:aco_tau}. $L_{k}$ é o custo dado pelo caminho percorrido pela formiga $k$th sendo tipicamente a distância percorrida e $Q$ é uma constante.

\begin{equation}
\label{eq:aco_tau}
    \tau_{xy} \leftarrow
    (1-\rho)\tau_{xy} + \sum_{k}\Delta \tau^{k}_{xy}
\end{equation}

\subsection{PSO}

A otimização do enxame de partículas (PSO). É um método de otimização aleatório baseado em população que foi inspirado no comportamento de bando de pássaros ou cardume de peixes. No PSO, cada solução é um “pássaro” no espaço de busca. Chamamos isso de “partícula”. Um enxame dessas partículas se move através do espaço de busca para encontrar uma posição ideal. Cada partícula possui uma posição e uma velocidade no espaço do problema -dimensional, onde denota a ésima partícula e representa a dimensão do problema ou número de variáveis desconhecidas. O PSO é inicializado com um grupo de partículas aleatórias (soluções) e, em seguida, procura por ótimo atualizando gerações. Durante cada iteração, cada partícula é atualizada seguindo dois valores “melhores”. O primeiro é o vetor posição da melhor solução (aptidão) que esta partícula alcançou até agora. O valor de aptidão também é armazenado. Esta posição é chamada de $pbest$. Outra posição “melhor” que é rastreada pelo otimizador do enxame de partículas é a melhor posição, obtida até agora, por qualquer partícula na população. Esta melhor posição é a melhor global atual e é chamada de $gbest$. Depois de encontrar os dois melhores valores, a posição e a velocidade das partículas são atualizadas pelas duas equações \ref{eq:pso_vk} \cite{jaberipour2011particle}.

\begin{equation}
\label{eq:pso_vk}
    \begin{gathered}
    v_i^k=wv_i^k+c_1r_1{(\mathrm{pbest}_i^k-x_i^k)}+c_2r_2{(\mathrm{gbest}^k-x_i^k)} \\
    x_i^{k+1}=x_i^k+v_i^{k+1}
    \end{gathered}
\end{equation}

Em que $v_i^k$ é a velocidade de cada partícula $i$ na iteração $k$, $x_i^{k}$ é a solução (posição) de cada partícula $i$ na iterção $k$. $c_1$ e $c_2$ são constantes positivas enquanto que $r_1$ e $r_2$ são duas variáveis aleatórios de distribuição uniforme entre 0 e 1. Ainda sobre a equação de atualização da velocidade da partícula,  $w$ é o peso inercial responsável por causar um efeito inercial da velocidade anterior na atual. Pode-se estabelecer um limite de velocidade em todas as dimensões, saturando a velocidade da partícula. \cite{jaberipour2011particle}.

\subsection{SARIMAX ACO-PSO Search}


\subsection{Algoritmo Genético}

Neste trabalho, o algoritmo genético é utilizado para hiper-parametrizar, quando se deseja obter parâmetros ótimos.
% TODO
% falar sobre aspectos gerais do AG e como eles são implementados
% no MLP e no ENSEMBLE

\section{Correção de resíduo}

\subsection{AG-MLP-Residual}

A metodologia utilizada consiste em gerar um modelo Hibrido entre um ARIMA (Autoregressive Integrated Moving Average) e duas ANN (Artificial Neural Networks). Utilizando para isto MLP (Mult Layer Perceptron). A primeira das redes neurais deve estimar o erro entre a série temporal real e a resultante do modelo ARIMA. Este tipo de modelagem já foi muito utilizada e discutida na literatura \cite{zhang2003time, khashei2010artificial, babu2014moving, de2014hybrid, de2016hybrid, domingos2019intelligent}. A segunda rede neural deve servir para gerar uma função linear de associação entre o modelo SARIMAX e a primeira rede neural.

Para obter as duas ANNs bem treinadas e parametrizadas, tanto para a função de associação não linear quanto para a previsão do erro, todo o modelo é envolto por busca baseado em um algoritmo genético. O algoritmo procura os melhores parâmetros para o MLP que estima o erro e o MLP que gera uma função não linear que associa o ARIMA puro e erro modelado como ilustrado pelo pseudo-Algoritmo.

Nesta busca, o algoritmo gera uma população de MLPs, com parâmetros aleatórios, avalia estes e ranqueia o melhores parâmetros. Depois disso, uma nova população é gerada, após um cruzamento entre melhores e piores MLPs. A melhor MLP é repetida na próxima geração. Depois do cruzamento, os parâmetros numéricos sofrem mutação. Esta nova população é re-avaliada e o ciclo continua.

Para todas as séries foi estipulado 80\% de dados para treino, que são utilizados para realizar o treinamento do algoritmo de otimização e hibridização, bem como todas as MLPs e 20\% para teste, que utilizado para avaliação do modelo híbrido final. Por cima disto, outra busca evolucionárias, é realizada para achar, as variáveis de Lag, quantidade de dados do passado que serão utilizados para prever o próximo dado futuro e Forecast, quantidade de previsões a partir de um modelo. As variáveis em questão são descritas:

\begin{itemize}

    \item Lag Error - Quantidade de amostras do passado utilizadas para prever a próxima amostra futura da serie temporal do erro entre a serie real e a do modelo ARIMA. Obtida sobre a serie do erro, é usado para modelar erro entre a serie original e a obtida pelo ARIMA.
    
    \item Forecast Association Error - Quantidade de amostras futuras geradas a partir do erro modelado. Usado para modelar função associativa entre erro modelado e serie ARIMA.
    
    \item Lag Association Error - Quantidades de amostras do passado do erro modelo.
    Usado para modelar função associativa entre erro modelado e serie ARIMA.
    
    \item Lag Association ARIMA - Quantidade de amostras do passado da serie do modelo ARIMA: obtida sobre a serie do ARIMA, é usada para modelar função associativa entre erro modelado e serie ARIMA.
    
\end{itemize}

O algoritmo evolucionário escolhido não leva em consideração a variabilidade implícita de treinamento de MLPs, entretanto este foi programado de forma a salvar a cada geração os modelos com os pesos treinados, não apenas as topologias.

Cada MLP utilizada no modelo híbrido proposto tem características como mostrado a seguir:
\begin{itemize}
    \item Função de Ativação {identidade, logística, tangente hiperbólica,
relu}
    \item Atualização da Taxa de Aprendizagem {constante, invscaling,
adaptativa}
    \item otimizador
    \item quantidade de neurônios nas camada escondida
\end{itemize}

\subsection{MLP Voting Regressor}

Este modelo é análogo ao anterior, porém com a diferença que ao invés de se escolher uma rede neural melhor para cada um 

\subsection{Voting Regressor Ensembles}